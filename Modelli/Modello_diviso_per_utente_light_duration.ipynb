{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cafabb6",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cce8d6",
   "metadata": {},
   "source": [
    "### Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from sklearn.metrics import *\n",
    "from keras.optimizers import Adam\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import keras.backend as K\n",
    "import keras\n",
    "from keras import layers\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c5b9e",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../dati_continui_con_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0640e454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[160:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carico elenco utenti per scorrere tutti gli id\n",
    "elenco_utenti = pd.read_csv('../../dataset/userinfo.csv')\n",
    "elenco_utenti.drop(elenco_utenti.columns[[0, 3]], axis=1, inplace=True) # drop colonne superflue\n",
    "elenco_utenti.columns = ['user_id', 'timezone', 'sex', 'age', 'height']\n",
    "elenco_utenti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_index(['user_id','date'], inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a91a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo una lista di di dataframe dove ogni elemento è l'insieme delle date per utente\n",
    "utenti = []\n",
    "\n",
    "# inserisco per ogni elemento della lista il dataframe relativo ad un utente presente nel dataset\n",
    "for i, r in elenco_utenti.iterrows():\n",
    "    utente = r['user_id']\n",
    "    if utente in dataset.index:\n",
    "        utenti.append(dataset.loc[utente])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimina stagionalità\n",
    "senza_stag = []\n",
    "for corrente in utenti:\n",
    "    if len(corrente) >=14:\n",
    "        lista_stag = []\n",
    "        lista_stag.append(corrente[['steps']].squeeze() - seasonal_decompose(corrente[['steps']], model='additive', period = 7).seasonal)\n",
    "        lista_stag.append(corrente[['bedin']].squeeze() - seasonal_decompose(corrente[['bedin']], model='additive', period = 7).seasonal)\n",
    "        lista_stag.append(corrente[['bedout']].squeeze() - seasonal_decompose(corrente[['bedout']], model='additive', period = 7).seasonal)\n",
    "        lista_stag.append(corrente[['sleep duration']].squeeze() - seasonal_decompose(corrente[['sleep duration']], model='additive', period = 7).seasonal)\n",
    "        lista_stag.append(corrente[['deepduration']].squeeze()  - seasonal_decompose(corrente[['sleep duration']], model='additive', period = 7).seasonal)\n",
    "        lista_stag.append(corrente[['lightduration']].squeeze() - seasonal_decompose(corrente[['sleep duration']], model='additive', period = 7).seasonal)\n",
    "        frame = {'steps' : lista_stag[0], 'bedin' : lista_stag[1], 'bedout' : lista_stag[2], 'sleep duration' : lista_stag[3], 'deepduration' : lista_stag[4], 'lightduration' : lista_stag[5]}\n",
    "        senza_stag.append(pd.DataFrame(frame))\n",
    "utenti = senza_stag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88719ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione normalizzazione\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "def normalizza(dat):\n",
    "    df_for_training_scaled = scaler.fit_transform(dat)\n",
    "    return df_for_training_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adesso normalizza ogni dataset\n",
    "utenti_normalizzati = []\n",
    "for u in utenti:\n",
    "    utenti_normalizzati.append(normalizza(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_past is the number of step we will look in the past to predict the next target value.\n",
    "col2pred = 5  # 0:steps, 1:bedin, 2:bedout, 3:sleep duration, 4:deep duration, 5:lightduration\n",
    "window_size = 7\n",
    "def createXY(dataset,n_past):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(n_past, len(dataset)):\n",
    "            #per ogni feature fa l'append dei precedenti\n",
    "            dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])  \n",
    "            dataY.append(dataset[i,col2pred])\n",
    "    return np.array(dataX),np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ea065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea insieme di train\n",
    "train_lista = utenti_normalizzati[:7000]\n",
    "\n",
    "trainX_lista = []\n",
    "trainY_lista = []\n",
    "\n",
    "for t in train_lista:\n",
    "    trainX_temp, trainY_temp = createXY(t,window_size)\n",
    "    if len(trainX_temp.shape) == 3 and len(trainY_temp.shape) == 1:\n",
    "        trainX_lista.append(trainX_temp)\n",
    "        trainY_lista.append(trainY_temp)\n",
    "\n",
    "trainX = np.concatenate(trainX_lista)\n",
    "trainY = np.concatenate(trainY_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c43a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea insieme di test\n",
    "test_lista = utenti_normalizzati[7000:]\n",
    "\n",
    "testX_lista = []\n",
    "testY_lista = []\n",
    "\n",
    "for t in test_lista:\n",
    "    testX_temp, testY_temp = createXY(t,window_size)\n",
    "    if len(testX_temp.shape) == 3 and len(testY_temp.shape) == 1:\n",
    "        testX_lista.append(testX_temp)\n",
    "        testY_lista.append(testY_temp)\n",
    "\n",
    "testX = np.concatenate(testX_lista)\n",
    "testY = np.concatenate(testY_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce20569",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape, testX.shape, trainY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba19cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features num\n",
    "features_num = dataset.shape[1]\n",
    "features_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b413f",
   "metadata": {},
   "source": [
    "# Metriche di valutazione (MAE-MSE-RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(true_value_train, pred_value_train, true_value_test, pred_value_test):\n",
    "    print(\"**********TRAIN-SET***********\")\n",
    "    print(\"MAE: {:.3f}\".format(mean_absolute_error(\n",
    "        true_value_train, pred_value_train)))\n",
    "    print(\"MSE: {:.3f}\".format(\n",
    "        mean_squared_error(true_value_train, pred_value_train)))\n",
    "    print(\"RMSE: {:.3f}\".format(\n",
    "        mean_squared_error(true_value_train, pred_value_train, squared=True)))\n",
    "    # metrics test set\n",
    "    print(\"**********TEST-SET***********\")\n",
    "    print(\"MAE: {:.3f}\".format(mean_absolute_error(\n",
    "        true_value_test, pred_value_test)))\n",
    "    print(\"MSE: {:.3f}\".format(\n",
    "        mean_squared_error(true_value_test, pred_value_test)))\n",
    "    print(\"RMSE: {:.3f}\".format(\n",
    "        mean_squared_error(true_value_test, pred_value_test, squared=True)))\n",
    "    \n",
    "\n",
    "    plt.plot(true_value_test[:150], color='red', label='Real light duration')\n",
    "    plt.plot(pred_value_test[:150], color='blue', label='Predicted light duration')\n",
    "    plt.title('Light duration Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Light duration')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6547ba90",
   "metadata": {},
   "source": [
    "# Data rescaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def values4metrics(model, trainX, trainY, testX, testY):\n",
    "    prediction_train = model.predict(trainX)\n",
    "    prediction_train_copies_array = np.repeat(prediction_train, features_num, axis=-1)\n",
    "    pred_train = scaler.inverse_transform(np.reshape(prediction_train_copies_array, (len(prediction_train), features_num)))[:, col2pred]\n",
    "    true_value_train_copies_array = np.repeat(trainY, features_num, axis=-1)\n",
    "    true_value_train = scaler.inverse_transform(np.reshape(true_value_train_copies_array, (len(trainY), features_num)))[:, col2pred]\n",
    "\n",
    "    prediction_test = model.predict(testX)\n",
    "    prediction_copies_test_array = np.repeat(prediction_test,features_num, axis=-1)\n",
    "    pred_test = scaler.inverse_transform(np.reshape(prediction_copies_test_array,(len(prediction_test),features_num)))[:,col2pred]\n",
    "    true_value_test_copies_array = np.repeat(testY,features_num, axis=-1)\n",
    "    true_value_test = scaler.inverse_transform(np.reshape(true_value_test_copies_array,(len(testY),features_num)))[:,col2pred]\n",
    "    \n",
    "    return true_value_train, pred_train, true_value_test, pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e5b1b7",
   "metadata": {},
   "source": [
    "# Architetture di supporto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c259d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vec(Layer):\n",
    "\n",
    "    def __init__(self, output_dim=None, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(Time2Vec, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                shape=(input_shape[-1], self.output_dim),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.P = self.add_weight(name='P',\n",
    "                                shape=(input_shape[1], self.output_dim),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.w = self.add_weight(name='w',\n",
    "                                shape=(input_shape[1], 1),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.p = self.add_weight(name='p',\n",
    "                                shape=(input_shape[1], 1),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        super(Time2Vec, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        original = self.w * x + self.p\n",
    "        sin_trans = K.sin(K.dot(x, self.W) + self.P)\n",
    "\n",
    "        return K.concatenate([sin_trans, original], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe54ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(input_shape,head_size,num_heads,ff_dim,num_transformer_blocks,mlp_units,dropout=0,mlp_dropout=0):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"tanh\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "input_shape = trainX.shape[1:]\n",
    "\n",
    "model_transf = build_model(input_shape, head_size=256, num_heads=4, ff_dim=4, num_transformer_blocks=4, \n",
    "                        mlp_units=[128], mlp_dropout=0.4, dropout=0.25)\n",
    "\n",
    "model_transf.compile(loss=\"mse\", optimizer = Adam(learning_rate=1e-4))\n",
    "model_transf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab73305",
   "metadata": {},
   "source": [
    "# Funzione per richiamare i modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_recurrent(type = 'gru'):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if type == 'gru': # GRU\n",
    "        model.add(GRU(256, return_sequences=True, input_shape=(window_size, features_num)))\n",
    "        model.add(GRU(128, return_sequences=True))\n",
    "        model.add(GRU(64))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(32, activation = 'tanh'))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "    if type == 'lstm': # LSTM\n",
    "        model.add(LSTM(256, return_sequences=True,input_shape=(window_size, features_num)))\n",
    "        model.add(LSTM(128, return_sequences=True))\n",
    "        model.add(LSTM(64))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(32, activation='tanh'))\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    if type == 'bidirectional':  # Bidirectional-LSTM\n",
    "        model.add(Bidirectional(LSTM(256, return_sequences=True), input_shape=(window_size,features_num)))\n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "        model.add(Bidirectional(LSTM(64)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(32, activation='tanh'))\n",
    "        model.add(Dropout(0.5))   \n",
    "\n",
    "    if type == 'time2vec':  # Time2Vec-LSTM\n",
    "        model.add(Input(shape=(window_size, features_num)))\n",
    "        model.add(Time2Vec(120))\n",
    "        model.add(LSTM(256, return_sequences=True))\n",
    "        model.add(LSTM(128, return_sequences=True))\n",
    "        model.add(LSTM(64))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(32, activation='tanh'))\n",
    "        model.add(Dropout(0.5))  \n",
    "        \n",
    "    if type == 'cnn':  # CNN-LSTM\n",
    "        model.add(Conv1D(filters=256, kernel_size=2, activation='tanh', input_shape=(window_size,features_num)))\n",
    "        model.add(Conv1D(filters=128, kernel_size=2, activation='tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(RepeatVector(30))\n",
    "        model.add(LSTM(units=100, return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=100, return_sequences=True))\n",
    "        model.add(Dense(100, activation='tanh'))        \n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4393a4",
   "metadata": {},
   "source": [
    "# Iperparametri di allenamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = 4096  # 8192\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b57705",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d618ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = model_recurrent('gru')\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4974eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history_gru = model_gru.fit(trainX, trainY, epochs=n_epochs, batch_size=n_batch, verbose=1)\n",
    "end = time.time()\n",
    "time_gru = end-start;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9fdadf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_value_train_gru, pred_value_train_gru, true_value_test_gru, pred_value_test_gru = values4metrics(model_gru, trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d7e98",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50468a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_lstm = model_recurrent('lstm')\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5627609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history_lstm = model_lstm.fit(trainX, trainY, epochs = n_epochs, batch_size = n_batch, verbose=1)\n",
    "end = time.time()\n",
    "time_lstm = end-start;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043f87d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_value_train_lstm, pred_value_train_lstm, true_value_test_lstm, pred_value_test_lstm = values4metrics(model_lstm, trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf2039",
   "metadata": {},
   "source": [
    "# Bidirectional-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634ae0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bidirec = model_recurrent('bidirectional')\n",
    "model_bidirec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history_bidirect = model_bidirec.fit(trainX, trainY, epochs = n_epochs, batch_size = n_batch, verbose = 1)\n",
    "end = time.time()\n",
    "time_bi = end-start;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_value_train_bi, pred_value_train_bi, true_value_test_bi, pred_value_test_bi = values4metrics(model_bidirec, trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d49339b",
   "metadata": {},
   "source": [
    "# Time2Vec-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c11a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t2v = model_recurrent('time2vec')\n",
    "model_t2v.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c8663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history_t2v = model_t2v.fit(trainX, trainY, epochs = n_epochs, batch_size = n_batch, verbose = 1)\n",
    "end = time.time()\n",
    "time_t2v = end-start;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aeff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_value_train_t2v, pred_value_train_t2v, true_value_test_t2v, pred_value_test_t2v = values4metrics(model_t2v, trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3e7b5d",
   "metadata": {},
   "source": [
    "# CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = model_recurrent('time2vec')\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70505e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history_cnn = model_cnn.fit(trainX, trainY, epochs = n_epochs,  batch_size = n_batch, verbose=1)\n",
    "end = time.time()\n",
    "time_cnn = end-start;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee24241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_value_train_cnn, pred_value_train_cnn, true_value_test_cnn, pred_value_test_cnn = values4metrics(model_cnn, trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e925d0d",
   "metadata": {},
   "source": [
    "# T2V-Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history_t = model_transf.fit(trainX, trainY, epochs = n_epochs, batch_size = n_batch, verbose = 1)\n",
    "end = time.time()\n",
    "time_t = end-start;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_value_train_transf, pred_value_train_transf, true_value_test_trasnf, pred_value_test_transf = values4metrics(model_transf, trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712efc13",
   "metadata": {},
   "source": [
    "# Plot risultati "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- GRU ---\\n\\nTime: \" + str(time_gru))\n",
    "metrics(true_value_train_gru, pred_value_train_gru, true_value_test_gru, pred_value_test_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- LSTM ---\\n\\nTime: \" + str(time_lstm))\n",
    "metrics(true_value_train_lstm, pred_value_train_lstm, true_value_test_lstm, pred_value_test_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3158c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Bidirectional ---\\n\\nTime: \" + str(time_bi))\n",
    "metrics(true_value_train_bi, pred_value_train_bi, true_value_test_bi, pred_value_test_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab86d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Time2Vec - LSTM ---\\n\\nTime: \" + str(time_t2v))\n",
    "metrics(true_value_train_t2v, pred_value_train_t2v, true_value_test_t2v, pred_value_test_t2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dce0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- CNN - LSTM ---\\n\\nTime: \" + str(time_cnn))\n",
    "metrics(true_value_train_cnn, pred_value_train_cnn, true_value_test_cnn, pred_value_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d8aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Transformer ---\\n\\nTime: \" + str(time_t))\n",
    "metrics(true_value_train_transf, pred_value_train_transf, true_value_test_transf, pred_value_test_transf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4b4fd2252870ded9ed5bbb741847e4d846382e3dda5f0c9e0a86e88ef12f07d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
