{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cafabb6",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cce8d6",
   "metadata": {},
   "source": [
    "### Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Bidirectional, LSTM, SimpleRNN, Dropout, TimeDistributed, Layer, Input, Conv1D, MaxPooling1D, GlobalMaxPool1D\n",
    "from sklearn.metrics import *\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c5b9e",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dati_continui_con_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo una lista di di dataframe dove ogni elemento Ã¨ l'insieme delle date per utente\n",
    "utenti = []\n",
    "# carico elenco utenti per scorrere tutti gli id\n",
    "elenco_utenti = pd.read_csv('../dataset/userinfo.csv')\n",
    "elenco_utenti.drop(elenco_utenti.columns[[0, 3]], axis=1, inplace=True)\n",
    "elenco_utenti.columns = ['user_id', 'timezone', 'sex', 'age', 'height']\n",
    "elenco_utenti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_index(['user_id','date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a91a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserisco per ogni elemento della lista il dataframe relativo ad un utente presente nel dataset\n",
    "for i, r in elenco_utenti.iterrows():\n",
    "    utente = r['user_id']\n",
    "    if utente in dataset.index:\n",
    "        utenti.append(dataset.loc[utente])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88719ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione normalizzazione\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "def normalizza(dat):\n",
    "    df_for_training_scaled = scaler.fit_transform(dat)\n",
    "    return df_for_training_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adesso normalizza ogni dataset\n",
    "utenti_normalizzati = []\n",
    "for u in utenti:\n",
    "    utenti_normalizzati.append(normalizza(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784b600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(utenti_normalizzati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_past is the number of step we will look in the past to predict the next target value.\n",
    "col2pred = 4  # 0:steps, 1:bedin, 2:bedout, 3:sleep duration, 4:deep duration, 5:lightduration\n",
    "window_size = 7\n",
    "def createXY(dataset,n_past):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(n_past, len(dataset)):\n",
    "            #per ogni feature fa l'append dei precedenti\n",
    "            dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])  \n",
    "            dataY.append(dataset[i,col2pred])\n",
    "    return np.array(dataX),np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ea065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea insieme di train\n",
    "train_lista = utenti_normalizzati[:7000]\n",
    "\n",
    "trainX_lista = []\n",
    "trainY_lista = []\n",
    "\n",
    "for t in train_lista:\n",
    "    trainX_temp, trainY_temp = createXY(t,window_size)\n",
    "    if len(trainX_temp.shape) == 3 and len(trainY_temp.shape) == 1:\n",
    "        trainX_lista.append(trainX_temp)\n",
    "        trainY_lista.append(trainY_temp)\n",
    "\n",
    "trainX = np.concatenate(trainX_lista)\n",
    "trainY = np.concatenate(trainY_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c43a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea insieme di test\n",
    "test_lista = utenti_normalizzati[7000:]\n",
    "\n",
    "testX_lista = []\n",
    "testY_lista = []\n",
    "\n",
    "for t in test_lista:\n",
    "    testX_temp, testY_temp = createXY(t,window_size)\n",
    "    if len(testX_temp.shape) == 3 and len(testY_temp.shape) == 1:\n",
    "        testX_lista.append(testX_temp)\n",
    "        testY_lista.append(testY_temp)\n",
    "\n",
    "testX = np.concatenate(testX_lista)\n",
    "testY = np.concatenate(testY_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce20569",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape, testX.shape, trainY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba19cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features num\n",
    "features_num = dataset.shape[1]\n",
    "features_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85114462",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_cnn = trainX.reshape(trainX.shape[0], trainX.shape[1], trainX.shape[2], 1)\n",
    "\n",
    "\n",
    "def create_cnn_BiLSTM():\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=128, kernel_size=4, activation='tanh')))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=2, activation='tanh')))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(GlobalMaxPool1D()))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, activation='tanh')))\n",
    "    model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "\n",
    "    opt = Adam(learning_rate=0.0001)\n",
    "    model.compile(loss='mse', optimizer=opt)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_cnn_BiLSTM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4974eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(trainX_cnn, trainY, epochs = 5, verbose = 1, batch_size = 4096) # 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9fdadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train = model.predict(trainX_cnn)\n",
    "print(\"prediction\\n\", prediction_train)\n",
    "print(\"\\nPrediction Shape-\", prediction_train.shape)\n",
    "\n",
    "prediction_train_copies_array = np.repeat(prediction_train, features_num, axis=-1)\n",
    "pred_train = scaler.inverse_transform(np.reshape(prediction_train_copies_array, (len(prediction_train), features_num)))[:, col2pred]\n",
    "true_value_train_copies_array = np.repeat(trainY, features_num, axis=-1)\n",
    "true_value_train = scaler.inverse_transform(np.reshape(true_value_train_copies_array, (len(trainY), features_num)))[:, col2pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9073243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(true_value_train, pred_value_train):\n",
    "    print(\"**********TRAIN-SET***********\")\n",
    "    print(\"MAE: {:.3f}\".format(mean_absolute_error(\n",
    "        true_value_train, pred_value_train)))\n",
    "    print(\"MSE: {:.3f}\".format(\n",
    "        mean_squared_error(true_value_train, pred_value_train)))\n",
    "    print(\"RMSE: {:.3f}\".format(\n",
    "        mean_squared_error(true_value_train, pred_value_train, squared=True)))\n",
    "\n",
    "\n",
    "metrics(true_value_train, pred_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4b4fd2252870ded9ed5bbb741847e4d846382e3dda5f0c9e0a86e88ef12f07d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
